#!/bin/bash
#
# SAMPiD - Daemon for the SAMPi ECR tool (Last Modified 09/10/2015)
#
# This software should be set to run on every boot and will ensure that 
# the main Perl program which reads data via serial, logs it and prepares
# it for upload is running. 
#
# This daemon also uploads collected data via SFTP and periodically deletes
# data files older than a configurable threshold (default is 90 days)
# as these can be assumed to be safely on the server
#
# It is possible that an error will cause this process to crash so it is recommended
# that cron or a suitable scheduler attempt to run the daemon once every 10 minutes
# or similar to allow for automatic recovery without manual intervention

# Global Variables
ENABLE_LOGGING=1
LOCKDIR=/tmp/SAMPiD.lock
DAYS_TO_KEEP_DATA=90
USER=shopcsv
SERVER=wenzelsextranet.co.uk

cleanup()
{
    # Remove the lock directory
    if rmdir $LOCKDIR; then
        echo "SAMPiD shut down"
    else
        echo "Failed to remove lock directory '$LOCKDIR'"
        exit 1
    fi
}

# Main function
main() 
{
    # Attempt to create lock so only one instance runs concurrently (use directory because it is an atomic operation)
    if mkdir $LOCKDIR > /dev/null 2>&1; then
        # Link cleanup function to exit, should run if script crashes or is quit
        trap "cleanup" EXIT
    else
        echo "SAMPiD is already running, exiting" > /dev/tty
        exit 1
    fi

    # Main loop
    while true; do
        # Attempt to run SAMPi.pl (in the background) in case it is not already running or has crashed
        alreadyRunning=$(ps aux | grep -i "SAMPi.pl" | grep -v "grep" | wc -l)
        if (($alreadyRunning == 0)); then
            nohup $SAMPI_PATH/SAMPi.pl > /dev/null 2>&1 &
        fi

        # Attempt to upload the currently collected data via SFTP using rsync
        # This ensures that only the modified or new files are uploaded to the
        # server
        uploadData

        # Finally, clean up by deleting all data files modified more than a 
        # set number of days ago (default is 90 days)
        removeOldData

        sleep 300 # Wait for 5 minutes
    done
}

# Copy every new or modified file in the ecr_data directory to the server
uploadData()
{
    UPLOAD_PATH=$(dirname $SAMPI_PATH)/ecr_data
    echo "Uploading ECR data from $UPLOAD_PATH to server..."

    # rsync uses the archive, update (only send modified files), preserve time and verbose flags
    # rsync -autv $UPLOAD_PATH/* $USER@$SERVER

    # Update the local copy of the shops.csv file if required
    # rsync -autv $USER@$SERVER:/shops.csv $(dirname $SAMPI_PATH)
}

# Remove any data older than the threshold to preserve space on the device
removeOldData()
{
    echo "Removing data generated more than $DAYS_TO_KEEP_DATA days ago"
    find $UPLOAD_PATH -mtime +$DAYS_TO_KEEP_DATA -exec rm {} \;
}

# Set the correct path to SAMPi.pl depending on if we are in production or testing
if [[ $(uname) == 'Linux' ]]; then
    SAMPI_PATH=$HOME/SAMPi
else
    SAMPI_PATH=$HOME/Dropbox/Work/SAMPi/src
fi

# Send all output from this daemon to the system logger if enabled
if [[ $ENABLE_LOGGING == 1 ]]; then 
    exec 1> >(logger -t "SAMPiD") 2> >(logger -t "SAMPiD_ERROR")
fi

main "$@"

